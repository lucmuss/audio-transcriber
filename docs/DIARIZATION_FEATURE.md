# Speaker Diarization Feature

## Ãœbersicht

Das Speaker Diarization Feature ermÃ¶glicht die automatische Erkennung und Kennzeichnung verschiedener Sprecher in Audio-Aufnahmen. Dieses Feature nutzt das `gpt-4o-transcribe-diarize` Modell von OpenAI.

---

## âœ¨ Features

- âœ… Automatische Sprechererkennung
- âœ… Kennzeichnung von Sprecherwechseln
- âœ… Optionale Benennung bekannter Sprecher
- âœ… UnterstÃ¼tzung fÃ¼r Sprecher-Referenz-Audio
- âœ… Zeitstempel fÃ¼r jeden Sprecherbeitrag
- âœ… Dual-Output: JSON + Lesbare Textversion

---

## ðŸš€ Verwendung Ã¼ber die Kommandozeile

### Basis-Verwendung

Einfache Sprecherkennung ohne zusÃ¤tzliche Parameter:

```bash
audio-transcriber --input meeting.mp3 --enable-diarization
```

### Mit erwarteter Sprecheranzahl

Wenn Sie wissen, wie viele Sprecher erwartet werden:

```bash
audio-transcriber --input interview.mp3 --enable-diarization --num-speakers 2
```

### Mit bekannten Sprecher-Namen

Benennen Sie bekannte Sprecher im Voraus:

```bash
audio-transcriber --input podcast.mp3 --enable-diarization \
  --known-speaker-names Alice Bob
```

### Mit Sprecher-Referenz-Audio

FÃ¼r noch bessere Genauigkeit kÃ¶nnen Sie Referenz-Audiodateien angeben:

```bash
audio-transcriber --input meeting.wav --enable-diarization \
  --known-speaker-names "Agent" \
  --known-speaker-references agent.wav
```

**Wichtig:** Die Reihenfolge bei `--known-speaker-references` muss mit `--known-speaker-names` Ã¼bereinstimmen!

### VollstÃ¤ndiges Beispiel

```bash
audio-transcriber --input conference.mp3 \
  --enable-diarization \
  --num-speakers 3 \
  --known-speaker-names "Alice" "Bob" "Charlie" \
  --known-speaker-references alice_sample.wav bob_sample.wav charlie_sample.wav \
  --output-dir ./transcriptions \
  --segment-length 600 \
  --summarize
```

---

## ðŸ“‹ CLI-Parameter

| Parameter | Typ | Standard | Beschreibung |
|-----------|-----|----------|--------------|
| `--enable-diarization` | Flag | `False` | Aktiviert Speaker Diarization |
| `--num-speakers` | Integer | Auto | Erwartete Anzahl der Sprecher |
| `--known-speaker-names` | Liste | None | Namen bekannter Sprecher |
| `--known-speaker-references` | Liste | None | Pfade zu Referenz-Audiodateien |

---

## ðŸ“ Output-Struktur

Bei aktivierter Diarization werden **zwei Dateien** erstellt:

### 1. Diarized JSON (Roh-Format)
```
transcriptions/
â””â”€â”€ meeting_mp3_full.diarized_json
```

EnthÃ¤lt strukturierte JSON-Daten mit detaillierten Speaker-Informationen, Zeitstempeln und Text.

### 2. Readable Text (Human-Friendly)
```
transcriptions/
â””â”€â”€ meeting_mp3_full_readable.txt
```

Automatisch formatierte, lesbare Version:

```
Speaker 1: [00:00-00:15] Guten Morgen allerseits. Willkommen zu unserem wÃ¶chentlichen Meeting.

Speaker 2: [00:16-00:28] Danke! Ich mÃ¶chte gleich mit unserem ersten Thema beginnen.

Speaker 1: [00:29-00:45] Sehr gerne. Bitte fahren Sie fort.
```

---

## ðŸ”§ Technische Details

### Verwendetes Modell

Bei aktivierter Diarization wird automatisch das Modell gewechselt:
- **Standard:** `whisper-1`
- **Mit Diarization:** `gpt-4o-transcribe-diarize`

### Response Format

Die Diarization erzwingt automatisch das Format:
- **Format:** `diarized_json`
- **Chunking Strategy:** `auto`

### API-Aufruf-Struktur

Intern wird folgender API-Aufruf verwendet:

```python
response = client.audio.transcriptions.create(
    model="gpt-4o-transcribe-diarize",
    file=audio_file,
    response_format="diarized_json",
    chunking_strategy="auto",
    extra_body={
        "num_speakers": 2,  # optional
        "known_speaker_names": ["Alice", "Bob"],  # optional
        "known_speaker_references": ["data:audio/wav;base64,..."],  # optional
    }
)
```

---

## ðŸ’¡ Best Practices

### 1. Referenz-Audio verwenden

FÃ¼r beste Ergebnisse:
- **LÃ¤nge:** 5-30 Sekunden pro Sprecher
- **QualitÃ¤t:** Klare Stimme, wenig HintergrundgerÃ¤usch
- **Format:** WAV, MP3, oder M4A

### 2. Sprecher-Anzahl angeben

Wenn bekannt, verbessert `--num-speakers` die Genauigkeit:
- Bei **Interviews:** `--num-speakers 2`
- Bei **Meetings:** Anzahl der Teilnehmer angeben
- Bei **Podcasts:** Anzahl der Hosts + GÃ¤ste

### 3. Segmentierung beachten

Bei langen Aufnahmen:
- Diarization funktioniert **pro Segment**
- Standard: 600 Sekunden (10 Minuten)
- Kann mit `--segment-length` angepasst werden

### 4. Kosten im Blick behalten

Das `gpt-4o-transcribe-diarize` Modell kann teurer sein als Standard Whisper. ÃœberprÃ¼fen Sie die aktuellen Preise in der OpenAI-Dokumentation.

---

## ðŸŽ¯ AnwendungsfÃ¤lle

### Interviews
```bash
audio-transcriber --input interview.mp3 \
  --enable-diarization \
  --num-speakers 2 \
  --known-speaker-names "Interviewer" "Guest"
```

### Business Meetings
```bash
audio-transcriber --input team_meeting.mp3 \
  --enable-diarization \
  --summarize \
  --summary-prompt "Fasse das Meeting zusammen und liste Action Items auf."
```

### Podcasts
```bash
audio-transcriber --input podcast_episode.mp3 \
  --enable-diarization \
  --num-speakers 3 \
  --known-speaker-names "Host1" "Host2" "Guest"
```

### Call Center / Customer Support
```bash
audio-transcriber --input support_call.wav \
  --enable-diarization \
  --known-speaker-names "Agent" "Customer" \
  --known-speaker-references agent_voice.wav
```

### Gerichtsverhandlungen
```bash
audio-transcriber --input hearing.mp3 \
  --enable-diarization \
  --num-speakers 5 \
  --known-speaker-names "Judge" "Prosecutor" "Defense" "Witness" "Clerk"
```

---

## ðŸ” Diarized JSON Format

Das `diarized_json` Format enthÃ¤lt ein `segments` Array:

```json
{
  "segments": [
    {
      "speaker": "Speaker 1",
      "text": "Guten Morgen allerseits.",
      "start": 0.0,
      "end": 2.5
    },
    {
      "speaker": "Speaker 2",
      "text": "Guten Morgen!",
      "start": 2.6,
      "end": 3.8
    }
  ]
}
```

### Felder

- **speaker:** Name des Sprechers (z.B. "Speaker 1" oder "Alice")
- **text:** Gesprochener Text
- **start:** Startzeit in Sekunden
- **end:** Endzeit in Sekunden

---

## ðŸ› Troubleshooting

### Problem: Sprecher werden nicht korrekt erkannt

**LÃ¶sung:**
1. Referenz-Audio hinzufÃ¼gen mit `--known-speaker-references`
2. Anzahl der Sprecher mit `--num-speakers` vorgeben
3. AudioqualitÃ¤t verbessern (weniger HintergrundgerÃ¤usche)

### Problem: "Model not found" Fehler

**LÃ¶sung:**
- Stellen Sie sicher, dass Ihr OpenAI-Account Zugriff auf `gpt-4o-transcribe-diarize` hat
- ÃœberprÃ¼fen Sie die API-Key-Berechtigungen

### Problem: Zu viele/wenige Sprecher erkannt

**LÃ¶sung:**
- Nutzen Sie `--num-speakers` um die erwartete Anzahl vorzugeben
- Bei schwierigen Aufnahmen: Referenz-Audio verwenden

### Problem: Referenz-Audio wird nicht akzeptiert

**LÃ¶sung:**
- ÃœberprÃ¼fen Sie das Audio-Format (WAV, MP3, M4A unterstÃ¼tzt)
- Stellen Sie sicher, dass die Datei existiert und lesbar ist
- Pfad korrekt angeben (absolute oder relative Pfade)

---

## ðŸ“Š Vergleich: Mit vs. Ohne Diarization

### Ohne Diarization
```
Guten Morgen allerseits. Willkommen zu unserem Meeting. 
Danke! Ich mÃ¶chte gleich mit dem ersten Thema beginnen. 
Sehr gerne. Bitte fahren Sie fort.
```

### Mit Diarization
```
Speaker 1: [00:00-00:15] Guten Morgen allerseits. Willkommen zu unserem Meeting.

Speaker 2: [00:16-00:28] Danke! Ich mÃ¶chte gleich mit dem ersten Thema beginnen.

Speaker 1: [00:29-00:45] Sehr gerne. Bitte fahren Sie fort.
```

---

## ðŸ”— Integration mit anderen Features

### Mit Summarization
```bash
audio-transcriber --input meeting.mp3 \
  --enable-diarization \
  --summarize \
  --summary-prompt "Erstelle eine Zusammenfassung und ordne BeitrÃ¤ge den Sprechern zu."
```

### Mit Segmentierung
```bash
audio-transcriber --input long_conference.mp3 \
  --enable-diarization \
  --segment-length 900 \
  --overlap 15
```

### Mit verschiedenen Output-Formaten
**Hinweis:** Diar

ization Ã¼berschreibt das Response-Format zu `diarized_json`. FÃ¼r andere Formate (SRT, VTT) deaktivieren Sie Diarization.

---

## ðŸ’° Kosten-AbschÃ¤tzung

Die Kosten fÃ¼r Diarization hÃ¤ngen ab von:
- **Audio-LÃ¤nge:** Abgerechnet pro Minute
- **Modell-Preis:** `gpt-4o-transcribe-diarize` Preise siehe OpenAI-Preisliste
- **Segmentierung:** Mehrere Segmente = mehrere API-Calls

**Beispiel-Rechnung** (hypothetisch):
- 1-stÃ¼ndiges Meeting
- ~6 Segmente Ã  10 Minuten
- Preis: Check OpenAI Pricing fÃ¼r aktuelle Kosten

---

## ðŸŽ“ Erweiterte Nutzung

### Python API

```python
from audio_transcriber import AudioTranscriber
from pathlib import Path

transcriber = AudioTranscriber(api_key="sk-...")

result = transcriber.transcribe_file(
    file_path=Path("meeting.mp3"),
    output_dir=Path("./transcriptions"),
    enable_diarization=True,
    num_speakers=3,
    known_speaker_names=["Alice", "Bob", "Charlie"],
    known_speaker_references=[
        "alice.wav", 
        "bob.wav", 
        "charlie.wav"
    ]
)

print(f"Readable output: {result['readable_output']}")
```

### Batch-Processing

```bash
for file in ./audio_files/*.mp3; do
    audio-transcriber --input "$file" \
      --enable-diarization \
      --num-speakers 2 \
      --output-dir ./results
done
```

---

## ðŸ“ FAQ

**Q: Kann ich Diarization mit anderen Models (z.B. whisper-1) verwenden?**  
A: Nein, Diarization erfordert das `gpt-4o-transcribe-diarize` Modell.

**Q: Funktioniert Diarization mit lokalen Modellen (Ollama)?**  
A: Derzeit nur mit OpenAI's API. Lokale Diarization ist ein zukÃ¼nftiges Feature.

**Q: Wie viele Sprecher kann das System erkennen?**  
A: Theoretisch unbegrenzt, aber Genauigkeit sinkt bei >10 Sprechern.

**Q: Wird Diarization in SRT/VTT-Untertiteln unterstÃ¼tzt?**  
A: Aktuell nicht - das ist ein geplantes Feature.

**Q: Kann ich Sprecher nachtrÃ¤glich umbenennen?**  
A: Ja, bearbeiten Sie die JSON-Datei und verwenden Sie ein Script zur Konvertierung.

---

## ðŸš€ NÃ¤chste Schritte

- [ ] GUI-Integration (geplant)
- [ ] SRT/VTT mit Sprecher-Labels
- [ ] Automatisches Merging von Sprechern
- [ ] Sprecher-Statistiken (Redezeit, Wortanzahl)
- [ ] Export als strukturiertes Interview-Format

---

## ðŸ“ž Support & Feedback

Probleme oder VorschlÃ¤ge? Bitte erstellen Sie ein Issue auf GitHub!

**Letzte Aktualisierung:** Januar 2026  
**Version:** 1.0
